{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704abb2a-73ed-407d-8e43-82bb3c208023",
   "metadata": {},
   "source": [
    "# Convert GitHub Actions `.yaml` to Parallel Works ACTIVATE `.yaml`\n",
    "\n",
    "ACTIVATE `.yaml`-based workflows have the same \"feel\" as GitHub Actions so there are many similarities. However, they are not the same. GitHub Actions has a much wider feature set and `.yaml`s that run on GitHub runners have the advantage of implicit context with many additional environment variables.\n",
    "\n",
    "This notebook is a first draft, interactive tool for ingesting a GitHub Actions `.yaml`, clearing out some things that Parallel Works ACTIVATE definitely does not support, adding some boilerplate \"header\" information that is likely to be useful for ACTIVATE users, and keeping key workflow steps that ACTIVATE does support (namely the `jobs: steps: run:` framework and any explicit `env:` variables).\n",
    "\n",
    "This notebook is a work in progress and not a complete solution hence it is a living document and meant for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7a5ef3-a928-4e61-8f8b-c18e1b9abebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file=\"/home/sfgary/ubuntu-ci-x86_64-gnu.yaml\"\n",
    "output_file=input_file+\".2pw.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcc67de-41f1-4d2d-9933-6e13493c4e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dependencies may be already installed if running this notebook\n",
    "# within a JupyterLab instance.\n",
    "#!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8c6777-93fd-45a5-bbfd-4ec37abbef1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9217ec-0974-4a22-bbb8-5e320f0c706c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the file you want to convert\n",
    "with open(input_file) as stream:\n",
    "    try:\n",
    "        #print(yaml.safe_load(stream))\n",
    "        data = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c902cb21-689d-4c60-bbc7-1f4d03c7a7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', True, 'concurrency', 'defaults', 'env', 'jobs'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1062d481-d02f-48da-8dd8-82342eea335d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['env', 'jobs'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of som GitHub Actions things that ACTIVATE does not use\n",
    "data.pop('name')\n",
    "data.pop(True)\n",
    "data.pop('concurrency')\n",
    "data.pop('defaults')\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bfea22-5d7b-4d81-802d-3b31362c3cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runs-on': ['ubuntu-ci-c6a-x86_64'],\n",
       " 'steps': [{'name': 'cleanup',\n",
       "   'run': 'pwd\\nls -lart\\nset +e\\nfind ./* -type d -exec chmod u+xw {} \\\\;\\nset -e\\nrm -fr *\\n'},\n",
       "  {'name': 'checkout',\n",
       "   'uses': 'actions/checkout@v4',\n",
       "   'with': {'submodules': True}},\n",
       "  {'name': 'prepare-directories',\n",
       "   'run': '# DH* REVERT ME AFTER MERGE\\nmkdir -p ${BUILD_CACHE_PATH}\\nmkdir -p ${SOURCE_CACHE_PATH}\\n'},\n",
       "  {'name': 'create-buildcache',\n",
       "   'run': '# Get day of week to decide whether to use build caches or not\\nDOW=$(date +%u)\\n# Monday is 1 ... Sunday is 7\\nif [[ $DOW == 7 ]]; then\\n  export USE_BINARY_CACHE=false\\n  echo \"Ignore existing binary cache for creating buildcache environment\"\\nelse\\n  export USE_BINARY_CACHE=true\\n  echo \"Use existing binary cache for creating buildcache environment\"\\nfi\\n\\n# Set up spack-stack\\nsource ./setup.sh\\n\\ndeclare -a TEMPLATES=(\"unified-dev\" \"skylab-dev\" \"cylc-dev\" \"neptune-dev\")\\nfor TEMPLATE in \"${TEMPLATES[@]}\"; do\\n  if [[ \"${TEMPLATE}\" == *\"unified-dev\"* ]]; then\\n    export ENVNAME=ue-gcc-11.4.0-buildcache\\n  elif [[ \"${TEMPLATE}\" == *\"skylab-dev\"* ]]; then\\n    export ENVNAME=se-gcc-11.4.0-buildcache\\n  elif [[ \"${TEMPLATE}\" == *\"cylc-dev\"* ]]; then\\n    export ENVNAME=ce-gcc-11.4.0-buildcache\\n  elif [[ \"${TEMPLATE}\" == *\"neptune-dev\"* ]]; then\\n    export ENVNAME=ne-gcc-11.4.0-buildcache\\n  fi\\n  echo \"Creating environment ${ENVNAME} from template ${TEMPLATE}\"\\n\\n  export ENVDIR=$PWD/envs/${ENVNAME}\\n  spack stack create env --site linux.default --template ${TEMPLATE} --name ${ENVNAME} --compiler gcc\\n  spack env activate ${ENVDIR}\\n\\n  unset SPACK_DISABLE_LOCAL_CONFIG\\n  export SPACK_SYSTEM_CONFIG_PATH=\"${ENVDIR}/site\"\\n\\n  # Find external packages\\n  spack external find --scope system \\\\\\n      --exclude bison --exclude openssl \\\\\\n      --exclude curl --exclude python \\\\\\n      --exclude meson\\n  spack external find --scope system grep\\n  spack external find --scope system sed\\n  spack external find --scope system perl\\n  spack external find --scope system wget\\n  spack external find --scope system texlive\\n  spack external find --scope system mysql\\n\\n  # Find compilers\\n  spack compiler find --scope system\\n\\n  export SPACK_DISABLE_LOCAL_CONFIG=true\\n  unset SPACK_SYSTEM_CONFIG_PATH\\n\\n  # For buildcaches\\n  spack config add config:install_tree:padded_length:200\\n\\n  # Set compiler and MPI specs\\n  spack config add \"packages:mpi:require:[\\'openmpi@5.0.8\\']\"\\n  spack config add \"packages:all:prefer:[\\'%gcc\\']\"\\n\\n  # Add additional variants for MET packages, different from config/common/packages.yaml\\n  spack config add \"packages:met:variants:+python +grib2 +graphics +lidar2nc +modis\"\\n\\n  # Concretize and check for duplicates\\n  spack concretize --force --fresh 2>&1 | tee log.concretize.${ENVNAME}\\n  ${SPACK_STACK_DIR}/util/show_duplicate_packages.py -i fms -i crtm -i crtm-fix -i esmf -i mapl -i py-cython -i neptune-env\\n\\n  # Add and update source cache\\n  spack mirror add local-source file://${SOURCE_CACHE_PATH}/\\n  spack mirror create -a -d ${SOURCE_CACHE_PATH}/\\n\\n  # Add binary cache if requested\\n  if [ \"$USE_BINARY_CACHE\" = true ] ; then\\n    set +e\\n    spack mirror add local-binary file://${BUILD_CACHE_PATH}/\\n    spack buildcache update-index local-binary\\n    set -e\\n    echo \"Packages in spack binary cache:\"\\n    spack buildcache list\\n  fi\\n\\n  # Break installation up in pieces and create build caches in between\\n  # This allows us to \"spin up\" builds that altogether take longer than\\n  # six hours, and/or fail later in the build process.\\n\\n  if [[ \"${TEMPLATE}\" == *\"unified-dev\"* || \"${TEMPLATE}\" == *\"skylab-dev\"* ]]; then\\n    # base-env\\n    echo \"base-env ...\"\\n    spack install --fail-fast --source --no-check-signature base-env 2>&1 | tee log.install.${ENVNAME}.base-env\\n    spack buildcache create -u local-binary base-env\\n    # jedi-base-env\\n    echo \"jedi-base-env ...\"\\n    spack install --fail-fast --source --no-check-signature jedi-base-env 2>&1 | tee log.install.${ENVNAME}.jedi-base-env\\n    spack buildcache create -u local-binary jedi-base-env\\n    # jedi-ufs-env\\n    echo \"jedi-ufs-env ...\"\\n    spack install --fail-fast --source --no-check-signature jedi-ufs-env 2>&1 | tee log.install.${ENVNAME}.jedi-ufs-env\\n    spack buildcache create -u local-binary jedi-ufs-env\\n  elif [[ \"${TEMPLATE}\" == *\"neptune-dev\"* ]]; then\\n    # base-env\\n    echo \"base-env ...\"\\n    spack install --fail-fast --source --no-check-signature base-env 2>&1 | tee log.install.${ENVNAME}.base-env\\n    spack buildcache create -u local-binary base-env\\n    # neptune-python-env\\n    echo \"neptune-env ...\"\\n    spack install --fail-fast --source --no-check-signature neptune-python-env 2>&1 | tee log.install.${ENVNAME}.neptune-env\\n    spack buildcache create -u local-binary neptune-python-env\\n  fi\\n\\n  # the rest\\n  echo \"${TEMPLATE} ...\"\\n  spack install --fail-fast --source --no-check-signature 2>&1 | tee log.install.${ENVNAME}.all\\n  spack buildcache create -u local-binary\\n\\n  # Remove binary cache for next round of concretization\\n  if [ \"$USE_BINARY_CACHE\" = true ] ; then\\n    spack mirror rm local-binary\\n  fi\\n\\n  # Remove buildcache config settings\\n  spack config remove config:install_tree:padded_length\\n\\n  # Next steps: synchronize source and build cache to a central/combined mirror?\\n\\n  # Cleanup\\n  spack clean -a\\n  spack env deactivate\\n\\ndone\\n'},\n",
       "  {'name': 'create-env',\n",
       "   'run': '# Set up spack-stack\\nsource ./setup.sh\\nexport BUILDCACHE_ENVNAME=ue-gcc-11.4.0-buildcache\\nexport BUILDCACHE_ENVDIR=$PWD/envs/${BUILDCACHE_ENVNAME}\\nexport ENVNAME=ue-gcc-11.4.0\\nexport ENVDIR=$PWD/envs/${ENVNAME}\\nrsync -av --exclude=\\'install\\' --exclude=\\'spack.lock\\' --exclude=\\'.spack_db\\' ${BUILDCACHE_ENVDIR}/ ${ENVDIR}/\\nspack env activate ${ENVDIR}\\n\\n# Concretize and check for duplicates\\nspack concretize --force 2>&1 | tee log.concretize.${ENVNAME}\\n${SPACK_STACK_DIR}/util/show_duplicate_packages.py -i fms -i crtm -i crtm-fix -i esmf -i mapl -i py-cython -i neptune-env\\n\\n# Add binary cache back in\\nspack mirror add local-binary file://${BUILD_CACHE_PATH}/\\necho \"Packages in combined spack build caches:\"\\nspack buildcache list\\n\\n# Install from cache\\nspack install --fail-fast --source --no-check-signature 2>&1 | tee log.install.${ENVNAME}.all\\n\\n# Check shared libraries\\n${SPACK_STACK_DIR}/util/ldd_check.py $SPACK_ENV 2>&1 | tee log.ldd_check\\n\\n# Create modules\\nspack clean -a\\nspack module tcl refresh -y\\nspack stack setup-meta-modules\\nspack env deactivate\\n\\n# Test environment chaining\\necho \"Test environment chaining\"\\nspack stack create env --name chaintest --template empty --site linux.default --compiler gcc --upstream ${ENVDIR}/install\\n# Retain config from upstream so we don\\'t have to rebuild:\\ncp -r ${ENVDIR}/{site,common} $PWD/envs/chaintest/.\\nspack env activate ${PWD}/envs/chaintest\\nspack add nccmp@1.9.0.1%gcc\\nspack concretize | tee envs/chaintest/log.concretize\\nunwanted_duplicates=$(( cat envs/chaintest/log.concretize | grep -E \\'^ - \\' | grep -Fv \\'nccmp@1.9.0.1\\' || true ) | wc -l)\\nif [ ${unwanted_duplicates} -gt 0 ]; then echo \"Environment chaining test failed\"; exit 1; fi\\nspack env deactivate\\necho \"Verify \\'create env\\' warnings\"\\necho \"# nothing\" >> ${SPACK_STACK_DIR}/envs/chaintest/site/packages.yaml\\necho \"# nothing\" >> ${SPACK_STACK_DIR}/envs/chaintest/common/packages.yaml\\nspack stack create env --name chaintest3 --site linux.default --compiler gcc --upstream ${SPACK_STACK_DIR}/envs/chaintest/install 2>&1 | tee stderr.txt\\ncnt=$(grep -c \"WARNING.*do not match\" stderr.txt || true)\\nif [ $cnt -lt 3 ]; then echo \"Missing \\'create env\\' warnings\"; exit 1; fi\\n'},\n",
       "  {'name': 'test-env',\n",
       "   'run': 'source /etc/profile.d/modules.sh\\nmodule use /home/ubuntu/spack-stack/modulefiles\\n\\nexport ENVNAME=ue-gcc-11.4.0\\nexport ENVDIR=$PWD/envs/${ENVNAME}\\nls -l ${ENVDIR}/install/modulefiles/Core\\n\\nmodule use ${ENVDIR}/install/modulefiles/Core\\nmodule load stack-gcc/11.4.0\\nmodule load stack-openmpi/5.0.8\\nmodule available\\n\\nmodule load jedi-ufs-env\\nmodule load ewok-env\\nmodule load soca-env\\nmodule list\\n'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['jobs']['ubuntu-ci-c6a-x86_64-gnu-build']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74790ba8-806e-4140-aeac-be71d9920228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae6806-50db-47d6-bb28-64e87f2720a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change runs-on: to ssh:\n",
    "# Get list of jobs, header_items first, before iterating\n",
    "# because otherwise Python throws an error when size\n",
    "# of the dictionary changes during the iteration.\n",
    "\n",
    "jobs = list(data['jobs'].keys())\n",
    "for job in jobs:\n",
    "\n",
    "    header_items = list(data['jobs'][job].keys())\n",
    "    for header_item in header_items:\n",
    "        if header_item == \"runs-on\":\n",
    "            data['jobs'][job][\"ssh\"] = data['jobs'][job][\"runs-on\"]\n",
    "            data['jobs'][job][\"ssh\"] = list(\"remoteHost: ${{inputs.resource.ip}}\")\n",
    "            del data['jobs'][job][\"runs-on\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97927e82-8bd8-4602-a8e4-ca8ac976ce20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['jobs'][job].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379fc9e7-7987-4624-8244-cf36e36b2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env:\n",
      "  BUILD_CACHE_PATH: /home/ubuntu/spack-stack/build-cache-new-spack-v1\n",
      "  SOURCE_CACHE_PATH: /home/ubuntu/spack-stack/source-cache\n",
      "jobs:\n",
      "  ubuntu-ci-c6a-x86_64-gnu-build:\n",
      "    runs-on:\n",
      "    - ubuntu-ci-c6a-x86_64\n",
      "    steps:\n",
      "    - name: cleanup\n",
      "      run: 'pwd\n",
      "\n",
      "        ls -lart\n",
      "\n",
      "        set +e\n",
      "\n",
      "        find ./* -type d -exec chmod u+xw {} \\;\n",
      "\n",
      "        set -e\n",
      "\n",
      "        rm -fr *\n",
      "\n",
      "        '\n",
      "    - name: checkout\n",
      "      uses: actions/checkout@v4\n",
      "      with:\n",
      "        submodules: true\n",
      "    - name: prepare-directories\n",
      "      run: '# DH* REVERT ME AFTER MERGE\n",
      "\n",
      "        mkdir -p ${BUILD_CACHE_PATH}\n",
      "\n",
      "        mkdir -p ${SOURCE_CACHE_PATH}\n",
      "\n",
      "        '\n",
      "    - name: create-buildcache\n",
      "      run: \"# Get day of week to decide whether to use build caches or not\\nDOW=$(date\\\n",
      "        \\ +%u)\\n# Monday is 1 ... Sunday is 7\\nif [[ $DOW == 7 ]]; then\\n  export\\\n",
      "        \\ USE_BINARY_CACHE=false\\n  echo \\\"Ignore existing binary cache for creating\\\n",
      "        \\ buildcache environment\\\"\\nelse\\n  export USE_BINARY_CACHE=true\\n  echo \\\"\\\n",
      "        Use existing binary cache for creating buildcache environment\\\"\\nfi\\n\\n# Set\\\n",
      "        \\ up spack-stack\\nsource ./setup.sh\\n\\ndeclare -a TEMPLATES=(\\\"unified-dev\\\"\\\n",
      "        \\ \\\"skylab-dev\\\" \\\"cylc-dev\\\" \\\"neptune-dev\\\")\\nfor TEMPLATE in \\\"${TEMPLATES[@]}\\\"\\\n",
      "        ; do\\n  if [[ \\\"${TEMPLATE}\\\" == *\\\"unified-dev\\\"* ]]; then\\n    export ENVNAME=ue-gcc-11.4.0-buildcache\\n\\\n",
      "        \\  elif [[ \\\"${TEMPLATE}\\\" == *\\\"skylab-dev\\\"* ]]; then\\n    export ENVNAME=se-gcc-11.4.0-buildcache\\n\\\n",
      "        \\  elif [[ \\\"${TEMPLATE}\\\" == *\\\"cylc-dev\\\"* ]]; then\\n    export ENVNAME=ce-gcc-11.4.0-buildcache\\n\\\n",
      "        \\  elif [[ \\\"${TEMPLATE}\\\" == *\\\"neptune-dev\\\"* ]]; then\\n    export ENVNAME=ne-gcc-11.4.0-buildcache\\n\\\n",
      "        \\  fi\\n  echo \\\"Creating environment ${ENVNAME} from template ${TEMPLATE}\\\"\\\n",
      "        \\n\\n  export ENVDIR=$PWD/envs/${ENVNAME}\\n  spack stack create env --site\\\n",
      "        \\ linux.default --template ${TEMPLATE} --name ${ENVNAME} --compiler gcc\\n\\\n",
      "        \\  spack env activate ${ENVDIR}\\n\\n  unset SPACK_DISABLE_LOCAL_CONFIG\\n  export\\\n",
      "        \\ SPACK_SYSTEM_CONFIG_PATH=\\\"${ENVDIR}/site\\\"\\n\\n  # Find external packages\\n\\\n",
      "        \\  spack external find --scope system \\\\\\n      --exclude bison --exclude\\\n",
      "        \\ openssl \\\\\\n      --exclude curl --exclude python \\\\\\n      --exclude meson\\n\\\n",
      "        \\  spack external find --scope system grep\\n  spack external find --scope\\\n",
      "        \\ system sed\\n  spack external find --scope system perl\\n  spack external\\\n",
      "        \\ find --scope system wget\\n  spack external find --scope system texlive\\n\\\n",
      "        \\  spack external find --scope system mysql\\n\\n  # Find compilers\\n  spack\\\n",
      "        \\ compiler find --scope system\\n\\n  export SPACK_DISABLE_LOCAL_CONFIG=true\\n\\\n",
      "        \\  unset SPACK_SYSTEM_CONFIG_PATH\\n\\n  # For buildcaches\\n  spack config add\\\n",
      "        \\ config:install_tree:padded_length:200\\n\\n  # Set compiler and MPI specs\\n\\\n",
      "        \\  spack config add \\\"packages:mpi:require:['openmpi@5.0.8']\\\"\\n  spack config\\\n",
      "        \\ add \\\"packages:all:prefer:['%gcc']\\\"\\n\\n  # Add additional variants for\\\n",
      "        \\ MET packages, different from config/common/packages.yaml\\n  spack config\\\n",
      "        \\ add \\\"packages:met:variants:+python +grib2 +graphics +lidar2nc +modis\\\"\\n\\\n",
      "        \\n  # Concretize and check for duplicates\\n  spack concretize --force --fresh\\\n",
      "        \\ 2>&1 | tee log.concretize.${ENVNAME}\\n  ${SPACK_STACK_DIR}/util/show_duplicate_packages.py\\\n",
      "        \\ -i fms -i crtm -i crtm-fix -i esmf -i mapl -i py-cython -i neptune-env\\n\\\n",
      "        \\n  # Add and update source cache\\n  spack mirror add local-source file://${SOURCE_CACHE_PATH}/\\n\\\n",
      "        \\  spack mirror create -a -d ${SOURCE_CACHE_PATH}/\\n\\n  # Add binary cache\\\n",
      "        \\ if requested\\n  if [ \\\"$USE_BINARY_CACHE\\\" = true ] ; then\\n    set +e\\n\\\n",
      "        \\    spack mirror add local-binary file://${BUILD_CACHE_PATH}/\\n    spack\\\n",
      "        \\ buildcache update-index local-binary\\n    set -e\\n    echo \\\"Packages in\\\n",
      "        \\ spack binary cache:\\\"\\n    spack buildcache list\\n  fi\\n\\n  # Break installation\\\n",
      "        \\ up in pieces and create build caches in between\\n  # This allows us to \\\"\\\n",
      "        spin up\\\" builds that altogether take longer than\\n  # six hours, and/or fail\\\n",
      "        \\ later in the build process.\\n\\n  if [[ \\\"${TEMPLATE}\\\" == *\\\"unified-dev\\\"\\\n",
      "        * || \\\"${TEMPLATE}\\\" == *\\\"skylab-dev\\\"* ]]; then\\n    # base-env\\n    echo\\\n",
      "        \\ \\\"base-env ...\\\"\\n    spack install --fail-fast --source --no-check-signature\\\n",
      "        \\ base-env 2>&1 | tee log.install.${ENVNAME}.base-env\\n    spack buildcache\\\n",
      "        \\ create -u local-binary base-env\\n    # jedi-base-env\\n    echo \\\"jedi-base-env\\\n",
      "        \\ ...\\\"\\n    spack install --fail-fast --source --no-check-signature jedi-base-env\\\n",
      "        \\ 2>&1 | tee log.install.${ENVNAME}.jedi-base-env\\n    spack buildcache create\\\n",
      "        \\ -u local-binary jedi-base-env\\n    # jedi-ufs-env\\n    echo \\\"jedi-ufs-env\\\n",
      "        \\ ...\\\"\\n    spack install --fail-fast --source --no-check-signature jedi-ufs-env\\\n",
      "        \\ 2>&1 | tee log.install.${ENVNAME}.jedi-ufs-env\\n    spack buildcache create\\\n",
      "        \\ -u local-binary jedi-ufs-env\\n  elif [[ \\\"${TEMPLATE}\\\" == *\\\"neptune-dev\\\"\\\n",
      "        * ]]; then\\n    # base-env\\n    echo \\\"base-env ...\\\"\\n    spack install --fail-fast\\\n",
      "        \\ --source --no-check-signature base-env 2>&1 | tee log.install.${ENVNAME}.base-env\\n\\\n",
      "        \\    spack buildcache create -u local-binary base-env\\n    # neptune-python-env\\n\\\n",
      "        \\    echo \\\"neptune-env ...\\\"\\n    spack install --fail-fast --source --no-check-signature\\\n",
      "        \\ neptune-python-env 2>&1 | tee log.install.${ENVNAME}.neptune-env\\n    spack\\\n",
      "        \\ buildcache create -u local-binary neptune-python-env\\n  fi\\n\\n  # the rest\\n\\\n",
      "        \\  echo \\\"${TEMPLATE} ...\\\"\\n  spack install --fail-fast --source --no-check-signature\\\n",
      "        \\ 2>&1 | tee log.install.${ENVNAME}.all\\n  spack buildcache create -u local-binary\\n\\\n",
      "        \\n  # Remove binary cache for next round of concretization\\n  if [ \\\"$USE_BINARY_CACHE\\\"\\\n",
      "        \\ = true ] ; then\\n    spack mirror rm local-binary\\n  fi\\n\\n  # Remove buildcache\\\n",
      "        \\ config settings\\n  spack config remove config:install_tree:padded_length\\n\\\n",
      "        \\n  # Next steps: synchronize source and build cache to a central/combined\\\n",
      "        \\ mirror?\\n\\n  # Cleanup\\n  spack clean -a\\n  spack env deactivate\\n\\ndone\\n\"\n",
      "    - name: create-env\n",
      "      run: '# Set up spack-stack\n",
      "\n",
      "        source ./setup.sh\n",
      "\n",
      "        export BUILDCACHE_ENVNAME=ue-gcc-11.4.0-buildcache\n",
      "\n",
      "        export BUILDCACHE_ENVDIR=$PWD/envs/${BUILDCACHE_ENVNAME}\n",
      "\n",
      "        export ENVNAME=ue-gcc-11.4.0\n",
      "\n",
      "        export ENVDIR=$PWD/envs/${ENVNAME}\n",
      "\n",
      "        rsync -av --exclude=''install'' --exclude=''spack.lock'' --exclude=''.spack_db''\n",
      "        ${BUILDCACHE_ENVDIR}/ ${ENVDIR}/\n",
      "\n",
      "        spack env activate ${ENVDIR}\n",
      "\n",
      "\n",
      "        # Concretize and check for duplicates\n",
      "\n",
      "        spack concretize --force 2>&1 | tee log.concretize.${ENVNAME}\n",
      "\n",
      "        ${SPACK_STACK_DIR}/util/show_duplicate_packages.py -i fms -i crtm -i crtm-fix\n",
      "        -i esmf -i mapl -i py-cython -i neptune-env\n",
      "\n",
      "\n",
      "        # Add binary cache back in\n",
      "\n",
      "        spack mirror add local-binary file://${BUILD_CACHE_PATH}/\n",
      "\n",
      "        echo \"Packages in combined spack build caches:\"\n",
      "\n",
      "        spack buildcache list\n",
      "\n",
      "\n",
      "        # Install from cache\n",
      "\n",
      "        spack install --fail-fast --source --no-check-signature 2>&1 | tee log.install.${ENVNAME}.all\n",
      "\n",
      "\n",
      "        # Check shared libraries\n",
      "\n",
      "        ${SPACK_STACK_DIR}/util/ldd_check.py $SPACK_ENV 2>&1 | tee log.ldd_check\n",
      "\n",
      "\n",
      "        # Create modules\n",
      "\n",
      "        spack clean -a\n",
      "\n",
      "        spack module tcl refresh -y\n",
      "\n",
      "        spack stack setup-meta-modules\n",
      "\n",
      "        spack env deactivate\n",
      "\n",
      "\n",
      "        # Test environment chaining\n",
      "\n",
      "        echo \"Test environment chaining\"\n",
      "\n",
      "        spack stack create env --name chaintest --template empty --site linux.default\n",
      "        --compiler gcc --upstream ${ENVDIR}/install\n",
      "\n",
      "        # Retain config from upstream so we don''t have to rebuild:\n",
      "\n",
      "        cp -r ${ENVDIR}/{site,common} $PWD/envs/chaintest/.\n",
      "\n",
      "        spack env activate ${PWD}/envs/chaintest\n",
      "\n",
      "        spack add nccmp@1.9.0.1%gcc\n",
      "\n",
      "        spack concretize | tee envs/chaintest/log.concretize\n",
      "\n",
      "        unwanted_duplicates=$(( cat envs/chaintest/log.concretize | grep -E ''^ -\n",
      "        '' | grep -Fv ''nccmp@1.9.0.1'' || true ) | wc -l)\n",
      "\n",
      "        if [ ${unwanted_duplicates} -gt 0 ]; then echo \"Environment chaining test\n",
      "        failed\"; exit 1; fi\n",
      "\n",
      "        spack env deactivate\n",
      "\n",
      "        echo \"Verify ''create env'' warnings\"\n",
      "\n",
      "        echo \"# nothing\" >> ${SPACK_STACK_DIR}/envs/chaintest/site/packages.yaml\n",
      "\n",
      "        echo \"# nothing\" >> ${SPACK_STACK_DIR}/envs/chaintest/common/packages.yaml\n",
      "\n",
      "        spack stack create env --name chaintest3 --site linux.default --compiler gcc\n",
      "        --upstream ${SPACK_STACK_DIR}/envs/chaintest/install 2>&1 | tee stderr.txt\n",
      "\n",
      "        cnt=$(grep -c \"WARNING.*do not match\" stderr.txt || true)\n",
      "\n",
      "        if [ $cnt -lt 3 ]; then echo \"Missing ''create env'' warnings\"; exit 1; fi\n",
      "\n",
      "        '\n",
      "    - name: test-env\n",
      "      run: 'source /etc/profile.d/modules.sh\n",
      "\n",
      "        module use /home/ubuntu/spack-stack/modulefiles\n",
      "\n",
      "\n",
      "        export ENVNAME=ue-gcc-11.4.0\n",
      "\n",
      "        export ENVDIR=$PWD/envs/${ENVNAME}\n",
      "\n",
      "        ls -l ${ENVDIR}/install/modulefiles/Core\n",
      "\n",
      "\n",
      "        module use ${ENVDIR}/install/modulefiles/Core\n",
      "\n",
      "        module load stack-gcc/11.4.0\n",
      "\n",
      "        module load stack-openmpi/5.0.8\n",
      "\n",
      "        module available\n",
      "\n",
      "\n",
      "        module load jedi-ufs-env\n",
      "\n",
      "        module load ewok-env\n",
      "\n",
      "        module load soca-env\n",
      "\n",
      "        module list\n",
      "\n",
      "        '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the final converted file\n",
    "with open(output_file, 'w') as stream:\n",
    "    try:\n",
    "        yaml.dump(data, stream, default_style='literal')    # Write a YAML representation of data\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "        \n",
    "print(yaml.dump(data))    # Output the document to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69eb743-a8a5-4788-8f4d-04fdfd6374cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
